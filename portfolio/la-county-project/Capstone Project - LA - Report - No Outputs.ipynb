{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting version of Capstone project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to import packages - (learn how to hide)\n",
    "import descartes\n",
    "\n",
    "import folium # map rendering library\n",
    "\n",
    "import geopandas as gpd\n",
    "from geopy.geocoders import Nominatim # convert an address into latitude and longitude values\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "\n",
    "import pandas as pd\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "import requests # library to handle requests\n",
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from shapely import wkt\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "from sklearn.cluster import KMeans # KMeans clustering \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the national debt being at an all-time high for the US, becoming more efficent at managing funds at the local-level could be a great opportunity to also maximize spending at a federal level (and nationwide). So this study is going to explore a dataset of various cities within a specific area that includes various socioeconomic factors, by grouping them into different groups and creating different benchmarks for each group. By using unsupervised machine learning models that help us cluster cities into groups, this would hopefully help us provide us with enough data to make informed decisions on how to use supervised machine learning techiques to create potential benchmarks and (logisical) models that cities can use to measure the effectiveness of current resources and predict future success. Once the data has been group accordingly, then we are going to grabbing location data from popular areas in each city to see if there is an indirect relationship that we can identify (for future studies)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Understanding that Los Angeles county ranks #1 for largest county population in the US (~10 Million - larger than US 41 states), the goal of this study is to use statisical analysis and machine learning techiques on this dataset to classify cities within LA County into groups of clusters that help indentify population averages, benchmarks and indicators of success for each group - based on a variety of socioeconomic factors (i.e., income, school enrollment, life expectancy, etc.). This will be helpful for city planning and future research purposes by building off the initial research (www.measureofamerica.org/los-angeles-county/). This framework will also be useful for inserting other Los Angeles datasets for classification purposes.\n",
    "\n",
    "Leveraging data made available by the County of Los Angeles at (www.data.lacounty.gov/), we will be using 'A Portrait of Los Angeles County using the Human Development Index: GIS Data' at (www.data.lacounty.gov/Community/A-Portrait-of-Los-Angeles-County-using-the-Human-D/j7aj-mn8v). HD Index explaination - (https://ssrc-static.s3.amazonaws.com/moa/PoLA%20Methodological%20Note.pdf)\n",
    "\n",
    "Once the cities have been grouped into clusters, we will be grabbing population locations for each city and grouping the location data by cluster for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI_CSV='A_Portrait_of_Los_Angeles_County_using_the_Human_Development_Index__GIS_Data.csv' # csv filename\n",
    "LA_HPI=pd.read_csv(LA_HPI_CSV) # Read in csv data into a pandas dataframe\n",
    "LA_HPI.head() # Dataframe preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning up data up by reformatting columns, dropping irrelevant columns, and converting coordinates into polygon objects for mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI.drop(columns=['GEO_TYPE','GEO_ID'],inplace=True) # Drop irrelevant columns\n",
    "LA_HPI_columns=['Polygon','City','Human Development Index', 'Life Expectancy', 'No HS Diplomas', 'Bachelors Degrees', 'Graduate Degrees',\n",
    "       'School Enrollment', 'Earnings', 'Health Index', 'Education Index', 'Income Index'] # Reformat column names\n",
    "LA_HPI.columns=LA_HPI_columns # Replace column names\n",
    "LA_HPI[\"Polygon\"]=LA_HPI[\"Polygon\"].apply(wkt.loads) # Create polygon object for graphing\n",
    "LA_HPI.head() # Dataframe preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 140 rows and 12 columns. One row for each city; along with various columns for factors that pertain to health, education, and living standards, along with name and geographic information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading and formatting the dataset into a pandas dataframe (to make it easy to manipulate, plot, map and analyze the data), we now create another dataframe that we can use for calculations by transforming our cleaned up 140x12 dataset into a 140x10 dataset by setting 'City' as the index and removing the 'Polygon' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI_Table=LA_HPI # Create table dataframe\n",
    "LA_HPI_Table=LA_HPI_Table.drop(columns='Polygon') # Drop city column from table dataframe\n",
    "LA_HPI_Table.set_index('City',inplace=True) # Set city names as index\n",
    "LA_HPI_Table.head() # Dataframe preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we take a look at how these different areas differ from city to city using maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates (latitude, longtitude) for Los Angeles County\n",
    "address='Los Angeles County, US'\n",
    "geolocator = Nominatim(user_agent=\"CA_explorer\")\n",
    "location = geolocator.geocode(address)\n",
    "latitude = location.latitude\n",
    "longitude = location.longitude\n",
    "\n",
    "# Converting 'Polygon' column from dataframe into geodataframe for plotting\n",
    "LA_HPI_gdf=gpd.GeoDataFrame(LA_HPI,geometry='Polygon')\n",
    "LA_HPI_gdf_json=LA_HPI_gdf.to_json() # Convert from geodataframe to json for choropleth map\n",
    "\n",
    "# Create map of Los Angeles County using latitude and longitude values\n",
    "map_LA_County = folium.Map(location=[latitude, longitude], zoom_start=9)\n",
    "\n",
    "# Map features\n",
    "LA_HPI_gdf_Points=folium.features.Choropleth(LA_HPI_gdf_json)\n",
    "map_LA_County.add_child(LA_HPI_gdf_Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of Cities within LA County (above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map of cities by category density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting features on map\n",
    "style_function = lambda x: {'fillColor': '#ffffff', \n",
    "                            'color':'#000000', \n",
    "                            'fillOpacity': 0.1, \n",
    "                            'weight': 0.1}\n",
    "highlight_function = lambda x: {'fillColor': '#000000', \n",
    "                                'color':'#000000', \n",
    "                                'fillOpacity': 0.50, \n",
    "                                'weight': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Enrollment_Geo=['City','School Enrollment']\n",
    "\n",
    "# Initialize the map:\n",
    "map_LA_County = folium.Map([latitude, longitude], zoom_start=9)\n",
    "\n",
    "choropleth=folium.Choropleth(\n",
    "    geo_data=LA_HPI_gdf_json,\n",
    "    name='choropleth',\n",
    "    data=LA_HPI[Enrollment_Geo],\n",
    "    columns=Enrollment_Geo,\n",
    "    key_on='feature.properties.City',\n",
    "    bins=9,\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=1.2,\n",
    "    legend_name='School Enrollment (%)',\n",
    "    highlight=True\n",
    ").add_to(map_LA_County)\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['City'],labels=False)\n",
    ")\n",
    "\n",
    "choropleth=folium.features.GeoJson(\n",
    "    LA_HPI_gdf_json,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=Enrollment_Geo,\n",
    "        aliases=['City: ','School Enrollment in population %: '],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "map_LA_County.add_child(choropleth)\n",
    "\n",
    "map_LA_County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of Cities within LA County by School Enrollment (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graduate_Geo=['City','Graduate Degrees']\n",
    "\n",
    "# Initialize the map:\n",
    "map_LA_County = folium.Map([latitude, longitude], zoom_start=9)\n",
    "\n",
    "choropleth=folium.Choropleth(\n",
    "    geo_data=LA_HPI_gdf_json,\n",
    "    name='choropleth',\n",
    "    data=LA_HPI[Graduate_Geo],\n",
    "    columns=Graduate_Geo,\n",
    "    key_on='feature.properties.City',\n",
    "    bins=9,\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=1.2,\n",
    "    legend_name='Graduate Degrees (%)',\n",
    "    highlight=True\n",
    ").add_to(map_LA_County)\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['City'],labels=False)\n",
    ")\n",
    "\n",
    "choropleth=folium.features.GeoJson(\n",
    "    LA_HPI_gdf_json,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=Graduate_Geo,\n",
    "        aliases=['City: ','Graduate degrees in population %: '],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "map_LA_County.add_child(choropleth)\n",
    "\n",
    "map_LA_County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of Cities within LA County by Graduate Degrees (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Earnings_Geo=['City','Earnings']\n",
    "\n",
    "# Initialize the map:\n",
    "map_LA_County = folium.Map([latitude, longitude], zoom_start=9)\n",
    "\n",
    "choropleth=folium.Choropleth(\n",
    "    geo_data=LA_HPI_gdf_json,\n",
    "    name='choropleth',\n",
    "    data=LA_HPI[Earnings_Geo],\n",
    "    columns=Earnings_Geo,\n",
    "    key_on='feature.properties.City',\n",
    "    bins=9,\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=1.2,\n",
    "    legend_name='Earnings ($)',\n",
    "    highlight=True\n",
    ").add_to(map_LA_County)\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['City'],labels=False)\n",
    ")\n",
    "\n",
    "choropleth=folium.features.GeoJson(\n",
    "    LA_HPI_gdf_json,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=Earnings_Geo,\n",
    "        aliases=['City: ','Earnings in population $: '],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "map_LA_County.add_child(choropleth)\n",
    "\n",
    "map_LA_County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of Cities within LA County by Earnings (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "No_HS_Geo=['City','No HS Diplomas']\n",
    "\n",
    "# Initialize the map:\n",
    "map_LA_County = folium.Map([latitude, longitude], zoom_start=9)\n",
    "\n",
    "choropleth=folium.Choropleth(\n",
    "    geo_data=LA_HPI_gdf_json,\n",
    "    name='choropleth',\n",
    "    data=LA_HPI[No_HS_Geo],\n",
    "    columns=No_HS_Geo,\n",
    "    key_on='feature.properties.City',\n",
    "    bins=9,\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=1.2,\n",
    "    legend_name='No HS Diplomas (%)',\n",
    "    highlight=True\n",
    ").add_to(map_LA_County)\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['City'],labels=False)\n",
    ")\n",
    "\n",
    "choropleth=folium.features.GeoJson(\n",
    "    LA_HPI_gdf_json,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=No_HS_Geo,\n",
    "        aliases=['City: ','No HS Diplomas in population %: '],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "map_LA_County.add_child(choropleth)\n",
    "\n",
    "map_LA_County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of Cities within LA County by No HS Diplomas (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDI_Geo=['City','Human Development Index']\n",
    "\n",
    "# Initialize the map:\n",
    "map_LA_County = folium.Map([latitude, longitude], zoom_start=9)\n",
    "\n",
    "choropleth=folium.Choropleth(\n",
    "    geo_data=LA_HPI_gdf_json,\n",
    "    name='choropleth',\n",
    "    data=LA_HPI[HDI_Geo],\n",
    "    columns=HDI_Geo,\n",
    "    key_on='feature.properties.City',\n",
    "    bins=9,\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=1.2,\n",
    "    legend_name='Human Development Index (1-10)',\n",
    "    highlight=True\n",
    ").add_to(map_LA_County)\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['City'],labels=False)\n",
    ")\n",
    "\n",
    "choropleth=folium.features.GeoJson(\n",
    "    LA_HPI_gdf_json,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=HDI_Geo,\n",
    "        aliases=['City: ','Human Development Index in population (1-10): '],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "map_LA_County.add_child(choropleth)\n",
    "\n",
    "map_LA_County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of Cities within LA County by Human Development Index (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bachelors_Geo=['City','Bachelors Degrees']\n",
    "\n",
    "# Initialize the map:\n",
    "map_LA_County = folium.Map([latitude, longitude], zoom_start=9)\n",
    "\n",
    "choropleth=folium.Choropleth(\n",
    "    geo_data=LA_HPI_gdf_json,\n",
    "    name='choropleth',\n",
    "    data=LA_HPI[Bachelors_Geo],\n",
    "    columns=Bachelors_Geo,\n",
    "    key_on='feature.properties.City',\n",
    "    bins=9,\n",
    "    fill_color='PuBu',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=1.2,\n",
    "    legend_name='Bachelors Degrees (%)',\n",
    "    highlight=True\n",
    ").add_to(map_LA_County)\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['City'],labels=False)\n",
    ")\n",
    "\n",
    "choropleth=folium.features.GeoJson(\n",
    "    LA_HPI_gdf_json,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=Bachelors_Geo,\n",
    "        aliases=['City: ','Bachelors Degrees in population (%): '],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "map_LA_County.add_child(choropleth)\n",
    "\n",
    "map_LA_County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of Cities within LA County by Bachelors Degrees (above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the different maps, we see a clear correlation between higher performing cities and their proximity to the ocean which is not surprising. But their also seems to be a line of high performing cities that run from the ocean through LA all the way up into the Angeles forest. Would be interesting the analyze the ages in these populations to see if this is predictive of general migration patterns as people progress throughout their careers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the data was clean-up and formatted, we then do a quick visual analysis of the data to get a better understanding of the overall distribution for the different categories. Using histograms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI_Table.hist(figsize=(25,25)) # Create hisogram table\n",
    "plt.show() # Plot histogram (remove pre-plot messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the histogram shows a a couple of different features.\n",
    "##### School Enrollment:\n",
    "Compared to the other charts, there doesn't seem to be the least amount of disparty between cities in this area, so seeing how this doesn't directly transfer to the greater disparity that we see with bachelor's degrees and earning, this could be worth investigating to see if these communities are doing a poor job of educating their residents or doing a poor job of retaining their residents once they are educated and higher-income earners. \\\n",
    "##### Graduate Degrees vs Bachelors Degrees:\n",
    "Seems like graduate degrees are a lot more concentrated then how Bachelors degrees are distributed around LA county.\n",
    "##### Redundent Indexes:\n",
    "Their doesn't seem to be any significant relationships between the indexes and their corresponding values, so we will be dropping these later to increase the predictive power of our clustering model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our general understanding of how different area of cities within LA County are performing in different areas, now we look to explore the strength of the relationships between the different variables by looking at the correlations, to help us determine what is important for our calculations that will help us classify the cities.\n",
    "\n",
    "After our intial exploratory data analysis, we now move onto the data cleaning phase by using machine learning to help determine which factors would be relevant for building our dimensions, clusters, and for further analysis.\n",
    "\n",
    "Since the goal of the study is to understand how the cities within Los Angeles county group together and differ, we will be using unsupervised machine learning methods in the form of PCA and k-means clustering -- to find out how many dimensions and clusters our data should be grouped together to give us the best results.\n",
    "\n",
    "First, we start off by standardizing our data in order to get a better understanding of the relationships within the variables. Then we create a heatmap and scatterplots to explore the relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI_fit=preprocessing.StandardScaler().fit(LA_HPI_Table).transform(LA_HPI_Table) # Standardizing and transforming dataset\n",
    "LA_HPI_fit=pd.DataFrame(LA_HPI_fit, columns=LA_HPI_Table.columns) # Converting into dataframe with the mathcing column names\n",
    "LA_HPI_corr=LA_HPI_fit.corr() # Create correlation analysis object\n",
    "sns.heatmap(LA_HPI_corr) # Map correlation analysis as heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of our dataset (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(LA_HPI, diag_kind='hist',size=2.85) # Create scatterplot of all the variables correlations using seaborn\n",
    "plt.show() # Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inital look at the strenghs of the different relationships from the correlation charts also shows us that there are clear redundancies between indexes and their corresponding values (i.e., life expectancy and health index). So we do a principal componenets analysis to make sure our dataset has enough predicitve power in it's first few columns, so that we can get rid of redundant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Eigenvecors and eigenvalues of Covariance matrix\n",
    "mean_vec = np.mean(LA_HPI_fit, axis=0)\n",
    "cov_mat = np.cov(LA_HPI_fit.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_pairs = [ (np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))] # Create a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs.sort(key = lambda x: x[0], reverse= True) # Sort from high to low\n",
    "# Calculation of Explained Variance from the eigenvalues\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)] # Individual explained variance\n",
    "cum_var_exp = np.cumsum(var_exp) # Cumulative explained variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT OUT THE EXPLAINED VARIANCES SUPERIMPOSED \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(var_exp)), var_exp, alpha=0.3333, align='center', label='individual explained variance', color = 'g')\n",
    "plt.step(range(len(cum_var_exp)), cum_var_exp, where='mid',label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "print(cum_var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that 3 components can account for 94.62% of variance in our dataset. So we remove redundent columns (to give our data greater predictive power) and then re-analyze the relationships between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI_fit_V2=LA_HPI_fit # Storing information onto new dataframe\n",
    "LA_HPI_fit_V2=LA_HPI_fit_V2.drop(columns=['Human Development Index','Health Index','Education Index','Income Index']) # Dropping redundent columns\n",
    "LA_HPI_corr_V2=LA_HPI_fit_V2.corr() # Build correlation object\n",
    "sns.heatmap(LA_HPI_corr_V2) # Create heatmap of correlation object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation matrix of refined dataset (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI_V2=LA_HPI # Create dataframe for scatterplots\n",
    "LA_HPI_V2=LA_HPI_V2.drop(columns=['Human Development Index','Health Index','Education Index','Income Index']) # Dropping redundent columns\n",
    "sns.pairplot(LA_HPI_V2, diag_kind='hist',size=2.85) # Create scatterplot of all the variables correlations using seaborn\n",
    "plt.show() # Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot matrix of refined dataset (above)\n",
    "\n",
    "Now that we are happy with our dataset we then re-do a principal component analysis to see how many dimensions we should split our data into, in order to give us the most predictive power per dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Eigenvecors and eigenvalues of Covariance matrix\n",
    "mean_vec = np.mean(LA_HPI_fit_V2, axis=0)\n",
    "cov_mat = np.cov(LA_HPI_fit_V2.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "# Create a list of (eigenvalue, eigenvector) tuples\n",
    "eig_pairs = [ (np.abs(eig_vals[i]),eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort from high to low\n",
    "eig_pairs.sort(key = lambda x: x[0], reverse= True)\n",
    "\n",
    "# Calculation of Explained Variance from the eigenvalues\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i/tot)*100 for i in sorted(eig_vals, reverse=True)] # Individual explained variance\n",
    "cum_var_exp = np.cumsum(var_exp) # Cumulative explained variance\n",
    "\n",
    "# PLOT OUT THE EXPLAINED VARIANCES SUPERIMPOSED \n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(range(len(var_exp)), var_exp, alpha=0.3333, align='center', label='individual explained variance', color = 'g')\n",
    "plt.step(range(len(cum_var_exp)), cum_var_exp, where='mid',label='cumulative explained variance')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_var_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca=PCA()\n",
    "pca.fit(LA_HPI_fit_V2)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our consolidated correlation matrix, our top 3 variables still account for 93.29% for variability for a dataset, so we will move forward with this 140 x 6 table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI_V2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given how most of the variance in the LA County datset can be explained through 3 'principal component' variables (from the analysis above), we use Prinicipal Component Analysis (PCA) to reduce the number of features from our dataset into 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca3 = PCA(n_components=3) # PCA object for grouping dataset into three dimensions, by 3 components\n",
    "x_3d = pca3.fit_transform(LA_HPI_fit_V2) # Fit to our dataset, then transform it based on the three dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_3d[:5,:] # Preview of our 3 dimensional dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca3=pd.DataFrame(x_3d) # Dataframe from principal component analysis of 3\n",
    "sns.pairplot(df_pca3) # Plot dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_3d[:,0],x_3d[:,2], alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming our data into 3 dimension (above), now we find out what would be our optimal k for using k-means to cluster the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop to collect 'sum of squared distances' for k-means clustering ranging from 1 to 15\n",
    "Sum_of_squared_distances = []\n",
    "K = range(1,15)\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k)\n",
    "    km = km.fit(LA_HPI_fit_V2)\n",
    "    Sum_of_squared_distances.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(K, Sum_of_squared_distances, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Sum_of_squared_distances')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that our biggest drop off in accuracy comes where K is equal to 3, so we will use that for our K-means clustering of the PCA below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=3) #Set a 3 KMeans clustering\n",
    "\n",
    "X_clustered=kmeans.fit_predict(LA_HPI_fit_V2) #Compute cluster centers and predict cluster indices\n",
    "\n",
    "LABEL_COLOR_MAP = {0:'r', 1: 'g', 2: 'b'} #Define our own color map\n",
    "label_color = [LABEL_COLOR_MAP[l] for l in X_clustered]\n",
    "\n",
    "# Plot the scatter digram\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.scatter(x_3d[:,0],x_3d[:,2], c=label_color, alpha=0.5) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Clusters formed from (3-Dimension) PCA data (above)\n",
    "\n",
    "We also visualiza how these groups cluster together based on the different dimensions that were created from PCA, along with mapping how the clusters form on a map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temp dataframe from our PCA projection data \"x_10d\"\n",
    "df=pd.DataFrame(x_3d)\n",
    "df['X_cluster']=X_clustered\n",
    "LA_HPI['Cluster']=X_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clustered # Our array of clusters that were formed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our array of clusters that were formed (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Seaborn's pairplot to visualize our feature interactions based on clusters\n",
    "sns.pairplot(df, hue='X_cluster', palette= 'Dark2', diag_kind='kde',size=1.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map of our PCA data based on the clusters that were formed using k-means (above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After our clusters of groups have been created, then we place the cluster data into our earlier graphs to get a better understanding of how LA County is broken down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Seaborn's pairplot to visualize our KMeans clustering on the PCA projected data\n",
    "sns.pairplot(LA_HPI, hue='Cluster', palette= 'Dark2', diag_kind='kde',size=1.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our original dataframe grouped by clusters (above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_HPI_V2['Cluster']=X_clustered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Seaborn's pairplot to visualize our KMeans clustering on the PCA projected data\n",
    "sns.pairplot(LA_HPI_V2, hue='Cluster', palette= 'Dark2', diag_kind='kde',size=1.85)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our refined dataframe grouped by clusters (above)\n",
    "\n",
    "Upon our initial research for how the factors correlated to each other, we discovered an interesting relationship between 'school enrollment', 'earnings' and 'bachelors degrees' that could warrant further analysis.\n",
    "\n",
    "To help faciliate further research, we grabbed location data from the top 3 popular places in each city using foursquare, and segmented by cluster below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials and Parameters\n",
    "CLIENT_ID = 'B3WEP1QRUXRIZQSZWGWO1JLR2P5XT1513G4K0ZLJ4AYAAZ12' # your Foursquare ID\n",
    "CLIENT_SECRET = 'REIU1MYR5KK4O1033IKMEG40YOUTCEBGBJNGH3FLSZVH4PSJ' # your Foursquare Secret\n",
    "VERSION = '20180605' # Foursquare API version\n",
    "LIMIT = 3\n",
    "INTENT='browse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VENUE_List=[]\n",
    "# for loop for column rows\n",
    "for i in range(len(LA_HPI)):\n",
    "    CITY=LA_HPI['City'][i]\n",
    "    CLUSTER=LA_HPI['Cluster'][i]\n",
    "    CITIES=LA_HPI['City'][i].split(\" - \")\n",
    "\n",
    "# for loop for column items\n",
    "    for j in range(len(CITIES)):\n",
    "        NEAR=CITIES[j] +', CA'\n",
    "\n",
    "        # create the API request URL\n",
    "        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&near={}&limit={}&intent={}'.format(\n",
    "            CLIENT_ID, \n",
    "            CLIENT_SECRET, \n",
    "            VERSION, \n",
    "            NEAR,  \n",
    "            LIMIT,\n",
    "            INTENT)\n",
    "            \n",
    "        # make the GET request\n",
    "        results = requests.get(url).json()\n",
    "        \n",
    "        if results['meta']['code']==200:\n",
    "            for k in range(LIMIT):\n",
    "                # Save relevant field from results into a dataframe\n",
    "                NAME=results['response']['groups'][0]['items'][k]['venue']['name']\n",
    "                CATEGORY=results['response']['groups'][0]['items'][k]['venue']['categories'][0]['name']\n",
    "                LOCATION=results['response']['geocode']['where']\n",
    "                AREA=CITY\n",
    "                GROUP=CLUSTER+1\n",
    "                VENUE=(NAME,CATEGORY,LOCATION,AREA,GROUP)\n",
    "                VENUE_List.append(VENUE)\n",
    "#                print(VENUE)\n",
    "        else:\n",
    "                    j=j+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select columns for dataframe to download results \n",
    "Venue_Columns=('Name','Category','City','Area','Group')\n",
    "# Convert list to dataframe, add columns\n",
    "df_VENUE_List=pd.DataFrame(VENUE_List,columns=Venue_Columns)\n",
    "# Formate 'city' column dataframe within the dataframe by Capitalizing it and removing the ' Ca' at the end\n",
    "df_VENUE_List['City']=df_VENUE_List['City'].str.title().str.rstrip(' Ca')\n",
    "# Save results into a csv\n",
    "df_VENUE_List.to_csv('LA_County_Venue_List.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Venue Location Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from csv\n",
    "df_VENUE_List_File=pd.read_csv('LA_County_Venue_List.csv')\n",
    "df_VENUE_List_File.drop(columns='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_Cluster_Data_1=LA_HPI[LA_HPI['Cluster']==0].mean()\n",
    "df_VENUE_List_File.loc[df_VENUE_List_File['Group'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_Cluster_Data_2=LA_HPI[LA_HPI['Cluster']==1].mean()\n",
    "df_VENUE_List_File.loc[df_VENUE_List_File['Group'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_Cluster_Data_3=LA_HPI[LA_HPI['Cluster']==2].mean()\n",
    "df_VENUE_List_File.loc[df_VENUE_List_File['Group'] == 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'Polygon' column from dataframe into geodataframe for plotting\n",
    "LA_HPI_gdf=gpd.GeoDataFrame(LA_HPI,geometry='Polygon')\n",
    "LA_HPI_gdf_json=LA_HPI_gdf.to_json() # Convert from geodataframe to json for choropleth map\n",
    "\n",
    "Cluster_Geo=['City','Cluster']\n",
    "\n",
    "# Initialize the map:\n",
    "map_LA_County = folium.Map([latitude, longitude], zoom_start=9)\n",
    "\n",
    "choropleth=folium.Choropleth(\n",
    "    geo_data=LA_HPI_gdf_json,\n",
    "    name='choropleth',\n",
    "    data=LA_HPI[Cluster_Geo],\n",
    "    columns=Cluster_Geo,\n",
    "    key_on='feature.properties.City',\n",
    "    bins=4,\n",
    "    fill_color='Set3',\n",
    "    fill_opacity=0.7,\n",
    "    line_opacity=1.2,\n",
    "    legend_name='Cluster',\n",
    "    highlight=True\n",
    ").add_to(map_LA_County)\n",
    "choropleth.geojson.add_child(\n",
    "    folium.features.GeoJsonTooltip(['City'],labels=False)\n",
    ")\n",
    "\n",
    "choropleth=folium.features.GeoJson(\n",
    "    LA_HPI_gdf_json,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=['City','Cluster','Human Development Index', 'Life Expectancy', 'No HS Diplomas', 'Bachelors Degrees', 'Graduate Degrees',\n",
    "       'School Enrollment', 'Earnings', 'Health Index', 'Education Index', 'Income Index'\n",
    "               ],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "map_LA_County.add_child(choropleth)\n",
    "\n",
    "\n",
    "map_LA_County"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the map, we see a clear positive relationship between higher performing cities and their proximiting to the ocean. We also see that inner cities regions with Los Angeles and the San Fernando Valley are the worst performers, to go along with the Lancaster region. There also seem to be pockets of higher former cities in pockers of more mountain areas as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_Clusters=[]\n",
    "LA_Clusters=pd.concat([LA_Cluster_Data_1,LA_Cluster_Data_2,LA_Cluster_Data_3],axis=1)\n",
    "LA_Clusters.sort_values(by='Human Development Index',axis=1,inplace=True)\n",
    "LA_Clusters=LA_Clusters.transpose().rename(columns = {'X_cluster':'Cluster'})\n",
    "LA_Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the breakdown of the averages for the different groups above, we see the least disparity in life expectancy and school enrollment, while we the highest disparity is seen in no HS diplomas, graduate degrees and earnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we grouped the cities within LA counties into clusters and have seen how they are plotted out on a map, it is very interesting to see how the different clusters seemed to be grouped throughout the area. There seems to be an obvious association between highest performing cities and their proximity to the ocean, but we also see highest performing cities among mountain regions which would be interesting to explore from an age perspective to see if this is representative of migration patterns within LA County. It's also worth noting how close the different city clusters are in their school enrollment levels, while there is a fair amount of discrepancy in other categories. This could also be worth further explaination in the form of creating a logistical regression model, and also seeing if this is a result of the quality of education in various regions or if it is a results of cities not retaining their citizens once they have become educated and involved in the workforce."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results of our studies, it seems like there could be a lot of good information to further explore education effective and migration patterns within LA to see how they effect earnings and graduation rates. An imporant question to ask is are higher performing areas offering better education and/or are higher earning individuals moving to these areas once they've reached a certain level of income. While this dataset was limited to factors that related to health, income and education -- we are fortunate that LA County has a great amount of dataset available that can evaluated under a similar model to help with other classification tasks. Once we understand the different clusters and where their greatest opportunities for improvements are, we can use these clusters to develop benchmarks and allocate resources where they will 'move the needle' the most."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
